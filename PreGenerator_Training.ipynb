{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreGenerator-Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNj4YBBmC9L6ic38Vd7fc0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakurin/SuperResolutionGAN-TF2.0/blob/master/PreGenerator_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4VgWBLlR_MA",
        "colab_type": "text"
      },
      "source": [
        "# PreGenerator-Training Pipeline\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVJebjGSQUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make default version tf2.0 in colab\n",
        "%tensorflow_version 2.x\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install tensorlayer\n",
        "import tensorlayer as tl\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Mean\n",
        "\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Colab \n",
        "import zipfile\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPoXcMD9BlpF",
        "colab_type": "text"
      },
      "source": [
        "## Load Data And Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9x8MsmRrHS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "12be9570-c3ca-4fcd-e6b3-2ec0f565025c"
      },
      "source": [
        "!git clone https://github.com/Vakurin/SuperResolutionGAN-TF2.0.git\n",
        "%cd SuperResolutionGAN-TF2.0/\n",
        "\n",
        "from models import model_generator\n",
        "from dataset import get_train_data\n",
        "\n",
        "generator = model_generator()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SuperResolutionGAN-TF2.0'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)\u001b[K\rremote: Counting objects:  10% (2/20)\u001b[K\rremote: Counting objects:  15% (3/20)\u001b[K\rremote: Counting objects:  20% (4/20)\u001b[K\rremote: Counting objects:  25% (5/20)\u001b[K\rremote: Counting objects:  30% (6/20)\u001b[K\rremote: Counting objects:  35% (7/20)\u001b[K\rremote: Counting objects:  40% (8/20)\u001b[K\rremote: Counting objects:  45% (9/20)\u001b[K\rremote: Counting objects:  50% (10/20)\u001b[K\rremote: Counting objects:  55% (11/20)\u001b[K\rremote: Counting objects:  60% (12/20)\u001b[K\rremote: Counting objects:  65% (13/20)\u001b[K\rremote: Counting objects:  70% (14/20)\u001b[K\rremote: Counting objects:  75% (15/20)\u001b[K\rremote: Counting objects:  80% (16/20)\u001b[K\rremote: Counting objects:  85% (17/20)\u001b[K\rremote: Counting objects:  90% (18/20)\u001b[K\rremote: Counting objects:  95% (19/20)\u001b[K\rremote: Counting objects: 100% (20/20)\u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects:   6% (1/16)\u001b[K\rremote: Compressing objects:  12% (2/16)\u001b[K\rremote: Compressing objects:  18% (3/16)\u001b[K\rremote: Compressing objects:  25% (4/16)\u001b[K\rremote: Compressing objects:  31% (5/16)\u001b[K\rremote: Compressing objects:  37% (6/16)\u001b[K\rremote: Compressing objects:  43% (7/16)\u001b[K\rremote: Compressing objects:  50% (8/16)\u001b[K\rremote: Compressing objects:  56% (9/16)\u001b[K\rremote: Compressing objects:  62% (10/16)\u001b[K\rremote: Compressing objects:  68% (11/16)\u001b[K\rremote: Compressing objects:  75% (12/16)\u001b[K\rremote: Compressing objects:  81% (13/16)\u001b[K\rremote: Compressing objects:  87% (14/16)\u001b[K\rremote: Compressing objects:  93% (15/16)\u001b[K\rremote: Compressing objects: 100% (16/16)\u001b[K\rremote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "Unpacking objects:   5% (1/20)   \rUnpacking objects:  10% (2/20)   \rUnpacking objects:  15% (3/20)   \rUnpacking objects:  20% (4/20)   \rUnpacking objects:  25% (5/20)   \rUnpacking objects:  30% (6/20)   \rUnpacking objects:  35% (7/20)   \rUnpacking objects:  40% (8/20)   \rremote: Total 20 (delta 3), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  45% (9/20)   \rUnpacking objects:  50% (10/20)   \rUnpacking objects:  55% (11/20)   \rUnpacking objects:  60% (12/20)   \rUnpacking objects:  65% (13/20)   \rUnpacking objects:  70% (14/20)   \rUnpacking objects:  75% (15/20)   \rUnpacking objects:  80% (16/20)   \rUnpacking objects:  85% (17/20)   \rUnpacking objects:  90% (18/20)   \rUnpacking objects:  95% (19/20)   \rUnpacking objects: 100% (20/20)   \rUnpacking objects: 100% (20/20), done.\n",
            "/content/SuperResolutionGAN-TF2.0\n",
            "TensorFlow Version: 2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix4idqhE_LwK",
        "colab_type": "text"
      },
      "source": [
        "## Global Var"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTsPhwk49djh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_FOR_SAVE_MODELS = '/content/drive/My Drive/SRGAN/pre-train/'\n",
        "EPOCHS  = 2500\n",
        "\n",
        "PATH_FOLDER_WITH_IMAGES  = '/tmp/Dataset/DIV2K_train_HR/'\n",
        "IMG_HR_SIZE = 256\n",
        "IMG_LR_SIZE = 64\n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLrGuY5FtdTW",
        "colab_type": "text"
      },
      "source": [
        "## Colab Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES5_DFxKuqa_",
        "colab_type": "code",
        "outputId": "931adad5-e3d3-460a-b6a7-a8d1a136da67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs7ceiGwu8w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff75ae62-5f9f-4f91-abc5-0d08a9ef43d0"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/SRGAN/DIV2K_train_HR.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/Dataset\")\n",
        "zip_ref.close()\n",
        "\n",
        "print('total training test images:', len(os.listdir(PATH_FOLDER_WITH_IMAGES)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training test images: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42HjWPff_PWg",
        "colab_type": "text"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CVIgIkr-bxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = get_train_data(IMG_HR_SIZE, IMG_LR_SIZE, BATCH_SIZE, PATH_FOLDER_WITH_IMAGES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n30HtuJ-7Nkh",
        "colab_type": "text"
      },
      "source": [
        "## Training Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enLpdaAU7MrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(step=tf.Variable(1),\n",
        "                                  psnr=tf.Variable(-1.0),\n",
        "                                  optimizer=generator_optimizer,\n",
        "                                  model=generator)\n",
        "\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                                    directory=checkpoint_dir,\n",
        "                                                    max_to_keep=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEstUnemGP_n",
        "colab_type": "text"
      },
      "source": [
        "### Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0daeh289GPvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_pre_train(train_ds, epochs, save_path='./pre-train-model.h5'):\n",
        "  \n",
        "  loss_mean = Mean()\n",
        "  n_step_epoch = round(epochs // BATCH_SIZE)\n",
        "\n",
        "  for epoch in range(n_step_epoch):\n",
        "    now = time.time()\n",
        "    for step, (lr, hr) in enumerate(train_ds):\n",
        "                \n",
        "        loss, generated_image = train_step(lr, hr)\n",
        "        loss_mean(loss)\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            loss_value = loss_mean.result()\n",
        "            loss_mean.reset_states()\n",
        "\n",
        "            print(f'{epoch * BATCH_SIZE}/{epochs}: loss = {loss_value.numpy():.3f},  ({time.time() - now} s)')\n",
        "            checkpoint_manager.save()\n",
        "        \n",
        "    # Save Image\n",
        "    if (epoch != 0) and (epoch * BATCH_SIZE % 10 == 0):\n",
        "          print('____SAVE_____')\n",
        "          tl.vis.save_images(generated_image.numpy(), [2, 4], os.path.join(save_path, 'pre-train_g_{}.png'.format(epoch)))\n",
        "          generator.save(os.path.join(save_path, 'pre-generator-{}.h5'.format(epoch * BATCH_SIZE)))\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "@tf.function\n",
        "def train_step(lr, hr):\n",
        "    with tf.GradientTape() as g_tape:\n",
        "        generated_image = generator(lr, training=True)\n",
        "        # Loss MSE\n",
        "        loss_value = tf.keras.losses.MeanSquaredError()(hr, generated_image)\n",
        "\n",
        "    gradients = g_tape.gradient(loss_value, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
        "\n",
        "    return loss_value, generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15AA5AKut0Z",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_c2gWLrZat",
        "colab_type": "code",
        "outputId": "1aa3d762-acda-4648-da80-5ede6e765d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        }
      },
      "source": [
        "generator_pre_train(train_ds, EPOCHS, save_path=PATH_FOR_SAVE_MODELS)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/2500: loss = 0.019,  (1.1226136684417725 s)\n",
            "4/2500: loss = 0.021,  (1.0921790599822998 s)\n",
            "8/2500: loss = 0.021,  (1.0913665294647217 s)\n",
            "12/2500: loss = 0.021,  (1.0995068550109863 s)\n",
            "16/2500: loss = 0.020,  (1.0974464416503906 s)\n",
            "20/2500: loss = 0.020,  (1.0884041786193848 s)\n",
            "____SAVE_____\n",
            "24/2500: loss = 0.020,  (1.0831165313720703 s)\n",
            "28/2500: loss = 0.020,  (1.1057724952697754 s)\n",
            "32/2500: loss = 0.020,  (1.044996738433838 s)\n",
            "36/2500: loss = 0.019,  (1.0598022937774658 s)\n",
            "40/2500: loss = 0.019,  (1.046924114227295 s)\n",
            "____SAVE_____\n",
            "44/2500: loss = 0.019,  (1.0613272190093994 s)\n",
            "48/2500: loss = 0.022,  (1.0685710906982422 s)\n",
            "52/2500: loss = 0.020,  (1.071953535079956 s)\n",
            "56/2500: loss = 0.019,  (1.0297062397003174 s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1d0553a6b333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_pre_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_FOR_SAVE_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-e9fc7d11f9ad>\u001b[0m in \u001b[0;36mgenerator_pre_train\u001b[0;34m(train_ds, epochs, save_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e9fc7d11f9ad>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(lr, hr)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    590\u001b[0m   \"\"\"\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   8281\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   8282\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8283\u001b[0;31m         tld.op_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   8284\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8285\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}