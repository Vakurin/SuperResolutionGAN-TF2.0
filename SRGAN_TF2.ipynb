{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN-TF2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f15AA5AKut0Z",
        "EIT9ajiSNQ9N"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM/8H57UKjarNmBXM3k+eaG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakurin/SuperResolutionGAN-TF2.0/blob/master/SRGAN_TF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4VgWBLlR_MA",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline SRGAN Training\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVJebjGSQUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make default version tf2.0 in colab\n",
        "%tensorflow_version 2.x \n",
        "!pip install tensorlayer \n",
        "\n",
        "import tensorlayer as tl\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Mean\n",
        "\n",
        "#import scipy\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht22y3wEnBq8",
        "colab_type": "code",
        "outputId": "6c3020c4-5469-42af-c019-dd93093a589f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!git clone https://github.com/Vakurin/SuperResolutionGAN-TF2.0.git\n",
        "%cd SuperResolutionGAN-TF2.0/\n",
        "\n",
        "from models import model_vgg19, model_discriminator, model_generator\n",
        "from dataset import get_train_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SuperResolutionGAN-TF2.0'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/17)\u001b[K\rremote: Counting objects:  11% (2/17)\u001b[K\rremote: Counting objects:  17% (3/17)\u001b[K\rremote: Counting objects:  23% (4/17)\u001b[K\rremote: Counting objects:  29% (5/17)\u001b[K\rremote: Counting objects:  35% (6/17)\u001b[K\rremote: Counting objects:  41% (7/17)\u001b[K\rremote: Counting objects:  47% (8/17)\u001b[K\rremote: Counting objects:  52% (9/17)\u001b[K\rremote: Counting objects:  58% (10/17)\u001b[K\rremote: Counting objects:  64% (11/17)\u001b[K\rremote: Counting objects:  70% (12/17)\u001b[K\rremote: Counting objects:  76% (13/17)\u001b[K\rremote: Counting objects:  82% (14/17)\u001b[K\rremote: Counting objects:  88% (15/17)\u001b[K\rremote: Counting objects:  94% (16/17)\u001b[K\rremote: Counting objects: 100% (17/17)\u001b[K\rremote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/13)\u001b[K\rremote: Compressing objects:  15% (2/13)\u001b[K\rremote: Compressing objects:  23% (3/13)\u001b[K\rremote: Compressing objects:  30% (4/13)\u001b[K\rremote: Compressing objects:  38% (5/13)\u001b[K\rremote: Compressing objects:  46% (6/13)\u001b[K\rremote: Compressing objects:  53% (7/13)\u001b[K\rremote: Compressing objects:  61% (8/13)\u001b[K\rremote: Compressing objects:  69% (9/13)\u001b[K\rremote: Compressing objects:  76% (10/13)\u001b[K\rremote: Compressing objects:  84% (11/13)\u001b[K\rremote: Compressing objects:  92% (12/13)\u001b[K\rremote: Compressing objects: 100% (13/13)\u001b[K\rremote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:   5% (1/17)   \rUnpacking objects:  11% (2/17)   \rUnpacking objects:  17% (3/17)   \rUnpacking objects:  23% (4/17)   \rUnpacking objects:  29% (5/17)   \rUnpacking objects:  35% (6/17)   \rUnpacking objects:  41% (7/17)   \rUnpacking objects:  47% (8/17)   \rUnpacking objects:  52% (9/17)   \rUnpacking objects:  58% (10/17)   \rUnpacking objects:  64% (11/17)   \rUnpacking objects:  70% (12/17)   \rUnpacking objects:  76% (13/17)   \rUnpacking objects:  82% (14/17)   \rUnpacking objects:  88% (15/17)   \rUnpacking objects:  94% (16/17)   \rUnpacking objects: 100% (17/17)   \rUnpacking objects: 100% (17/17), done.\n",
            "/content/SuperResolutionGAN-TF2.0\n",
            "TensorFlow Version: 2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVN6nxmLchwC",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg_3wWIgihnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HR_SIZE = 256\n",
        "IMG_LR_SIZE = 64\n",
        "CHANNELS = 3\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 320\n",
        "\n",
        "PATH_PRE_GENERATOR       = '/content/drive/My Drive/SRGAN/models/pre-train-model-3000.h5'\n",
        "\n",
        "PATH_FOR_SAVE_MODELS     = '/content/drive/My Drive/SRGAN/models/'\n",
        "PATH_FOR_SAVE_GEN_IMAGES = '/content/drive/My Drive/SRGAN/photos/'\n",
        "\n",
        "PATH_FOLDER_WITH_IMAGES  = '/tmp/Dataset/DIV2K_train_HR/'\n",
        "\n",
        "# Directory For TensorBoard\n",
        "train_summary_writer = tf.summary.create_file_writer('logs/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhV3A_5Dqg5B",
        "colab_type": "text"
      },
      "source": [
        "##(Optional for colab) Dataset Unzipping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTXO_mUDse7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "62038e76-79c9-4111-dec9-57c26de07ac5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzOMlGJnqUO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5145ef2d-b98b-4969-ce24-98ee83f2f79e"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/SRGAN/DIV2K_train_HR.zip\", 'r') # ~3 min\n",
        "zip_ref.extractall(\"/tmp/Dataset\")\n",
        "zip_ref.close()\n",
        "\n",
        "print('total training test images:', len(os.listdir(PATH_FOLDER_WITH_IMAGES)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training test images: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15AA5AKut0Z",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dzEwXAjr8U",
        "colab_type": "code",
        "outputId": "2bc4e774-151d-4ab0-957c-7ad8643f4e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "# Load All Files By Batch 4 \n",
        "train_ds = get_train_data(IMG_HR_SIZE, IMG_LR_SIZE, BATCH_SIZE, PATH_FOLDER_WITH_IMAGES)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TL] Match file list = ['0480.png', '0167.png', '0791.png', '0527.png', '0350.png', '0247.png', '0181.png', '0778.png', '0171.png', '0708.png', '0515.png', '0198.png', '0617.png', '0800.png', '0028.png', '0311.png', '0459.png', '0447.png', '0734.png', '0159.png', '0084.png', '0388.png', '0081.png', '0702.png', '0319.png', '0003.png', '0553.png', '0398.png', '0109.png', '0080.png', '0636.png', '0180.png', '0402.png', '0545.png', '0741.png', '0682.png', '0027.png', '0202.png', '0252.png', '0635.png', '0568.png', '0524.png', '0271.png', '0016.png', '0144.png', '0686.png', '0065.png', '0600.png', '0680.png', '0079.png', '0130.png', '0355.png', '0561.png', '0672.png', '0465.png', '0449.png', '0155.png', '0501.png', '0153.png', '0328.png', '0476.png', '0034.png', '0301.png', '0442.png', '0396.png', '0177.png', '0222.png', '0098.png', '0364.png', '0205.png', '0259.png', '0064.png', '0059.png', '0689.png', '0587.png', '0227.png', '0652.png', '0785.png', '0218.png', '0722.png', '0750.png', '0043.png', '0479.png', '0115.png', '0296.png', '0612.png', '0219.png', '0300.png', '0338.png', '0770.png', '0210.png', '0333.png', '0160.png', '0578.png', '0551.png', '0324.png', '0593.png', '0183.png', '0213.png', '0122.png', '0621.png', '0329.png', '0513.png', '0367.png', '0032.png', '0709.png', '0781.png', '0400.png', '0405.png', '0797.png', '0499.png', '0086.png', '0417.png', '0390.png', '0140.png', '0026.png', '0285.png', '0312.png', '0720.png', '0107.png', '0011.png', '0458.png', '0580.png', '0387.png', '0351.png', '0519.png', '0126.png', '0751.png', '0481.png', '0670.png', '0692.png', '0460.png', '0040.png', '0701.png', '0193.png', '0691.png', '0424.png', '0533.png', '0013.png', '0378.png', '0248.png', '0090.png', '0399.png', '0532.png', '0535.png', '0767.png', '0395.png', '0640.png', '0366.png', '0669.png', '0331.png', '0687.png', '0112.png', '0658.png', '0627.png', '0450.png', '0517.png', '0295.png', '0363.png', '0601.png', '0035.png', '0654.png', '0773.png', '0416.png', '0488.png', '0132.png', '0550.png', '0749.png', '0230.png', '0435.png', '0777.png', '0015.png', '0748.png', '0468.png', '0443.png', '0620.png', '0056.png', '0354.png', '0464.png', '0742.png', '0492.png', '0206.png', '0427.png', '0297.png', '0255.png', '0577.png', '0423.png', '0565.png', '0506.png', '0659.png', '0344.png', '0445.png', '0360.png', '0393.png', '0342.png', '0613.png', '0299.png', '0676.png', '0484.png', '0201.png', '0099.png', '0758.png', '0591.png', '0275.png', '0475.png', '0103.png', '0546.png', '0361.png', '0055.png', '0124.png', '0597.png', '0049.png', '0446.png', '0579.png', '0491.png', '0534.png', '0138.png', '0655.png', '0567.png', '0092.png', '0298.png', '0223.png', '0477.png', '0498.png', '0681.png', '0303.png', '0563.png', '0570.png', '0117.png', '0410.png', '0526.png', '0251.png', '0389.png', '0408.png', '0623.png', '0359.png', '0148.png', '0547.png', '0082.png', '0382.png', '0769.png', '0258.png', '0407.png', '0288.png', '0418.png', '0698.png', '0776.png', '0575.png', '0374.png', '0169.png', '0362.png', '0753.png', '0292.png', '0707.png', '0071.png', '0036.png', '0472.png', '0508.png', '0031.png', '0438.png', '0757.png', '0628.png', '0165.png', '0203.png', '0332.png', '0336.png', '0598.png', '0147.png', '0050.png', '0279.png', '0067.png', '0384.png', '0718.png', '0334.png', '0017.png', '0121.png', '0261.png', '0190.png', '0740.png', '0454.png', '0644.png', '0500.png', '0379.png', '0276.png', '0453.png', '0267.png', '0412.png', '0018.png', '0473.png', '0136.png', '0346.png', '0666.png', '0391.png', '0727.png', '0554.png', '0696.png', '0495.png', '0021.png', '0236.png', '0290.png', '0793.png', '0308.png', '0187.png', '0716.png', '0204.png', '0095.png', '0257.png', '0619.png', '0469.png', '0494.png', '0420.png', '0284.png', '0608.png', '0207.png', '0728.png', '0089.png', '0293.png', '0264.png', '0763.png', '0514.png', '0752.png', '0052.png', '0704.png', '0322.png', '0566.png', '0150.png', '0409.png', '0633.png', '0625.png', '0762.png', '0376.png', '0569.png', '0657.png', '0584.png', '0783.png', '0660.png', '0482.png', '0428.png', '0646.png', '0638.png', '0419.png', '0518.png', '0571.png', '0269.png', '0381.png', '0244.png', '0478.png', '0133.png', '0168.png', '0539.png', '0232.png', '0094.png', '0116.png', '0208.png', '0573.png', '0415.png', '0603.png', '0272.png', '0485.png', '0386.png', '0197.png', '0406.png', '0323.png', '0642.png', '0077.png', '0502.png', '0106.png', '0356.png', '0656.png', '0088.png', '0273.png', '0014.png', '0237.png', '0093.png', '0511.png', '0316.png', '0044.png', '0794.png', '0163.png', '0401.png', '0394.png', '0549.png', '0719.png', '0233.png', '0113.png', '0057.png', '0588.png', '0743.png', '0074.png', '0321.png', '0560.png', '0552.png', '0520.png', '0262.png', '0606.png', '0100.png', '0731.png', '0215.png', '0595.png', '0182.png', '0042.png', '0029.png', '0341.png', '0069.png', '0556.png', '0102.png', '0368.png', '0397.png', '0023.png', '0030.png', '0599.png', '0104.png', '0061.png', '0431.png', '0189.png', '0125.png', '0353.png', '0668.png', '0457.png', '0047.png', '0648.png', '0622.png', '0736.png', '0253.png', '0173.png', '0134.png', '0562.png', '0559.png', '0711.png', '0462.png', '0710.png', '0755.png', '0278.png', '0521.png', '0451.png', '0576.png', '0705.png', '0632.png', '0439.png', '0025.png', '0131.png', '0241.png', '0250.png', '0422.png', '0240.png', '0667.png', '0790.png', '0212.png', '0073.png', '0038.png', '0730.png', '0242.png', '0063.png', '0414.png', '0630.png', '0429.png', '0383.png', '0277.png', '0543.png', '0348.png', '0510.png', '0097.png', '0314.png', '0127.png', '0607.png', '0629.png', '0604.png', '0759.png', '0683.png', '0664.png', '0733.png', '0766.png', '0413.png', '0012.png', '0062.png', '0650.png', '0270.png', '0557.png', '0594.png', '0411.png', '0583.png', '0320.png', '0053.png', '0172.png', '0176.png', '0070.png', '0287.png', '0009.png', '0174.png', '0143.png', '0699.png', '0191.png', '0466.png', '0634.png', '0665.png', '0119.png', '0135.png', '0058.png', '0582.png', '0372.png', '0653.png', '0782.png', '0467.png', '0022.png', '0048.png', '0151.png', '0528.png', '0516.png', '0795.png', '0690.png', '0558.png', '0310.png', '0798.png', '0483.png', '0392.png', '0001.png', '0317.png', '0725.png', '0268.png', '0421.png', '0735.png', '0020.png', '0263.png', '0246.png', '0304.png', '0234.png', '0192.png', '0037.png', '0260.png', '0684.png', '0196.png', '0589.png', '0585.png', '0194.png', '0231.png', '0525.png', '0146.png', '0529.png', '0164.png', '0744.png', '0675.png', '0357.png', '0799.png', '0780.png', '0540.png', '0713.png', '0536.png', '0738.png', '0142.png', '0596.png', '0677.png', '0294.png', '0796.png', '0712.png', '0522.png', '0649.png', '0002.png', '0497.png', '0789.png', '0697.png', '0548.png', '0209.png', '0110.png', '0008.png', '0663.png', '0448.png', '0592.png', '0352.png', '0075.png', '0703.png', '0662.png', '0337.png', '0509.png', '0358.png', '0266.png', '0120.png', '0747.png', '0004.png', '0674.png', '0779.png', '0158.png', '0051.png', '0024.png', '0226.png', '0724.png', '0746.png', '0128.png', '0343.png', '0768.png', '0141.png', '0564.png', '0792.png', '0370.png', '0249.png', '0225.png', '0315.png', '0618.png', '0574.png', '0108.png', '0072.png', '0091.png', '0493.png', '0441.png', '0152.png', '0006.png', '0645.png', '0616.png', '0430.png', '0694.png', '0340.png', '0425.png', '0307.png', '0486.png', '0505.png', '0254.png', '0631.png', '0590.png', '0060.png', '0586.png', '0739.png', '0432.png', '0455.png', '0256.png', '0129.png', '0774.png', '0685.png', '0195.png', '0211.png', '0349.png', '0729.png', '0461.png', '0214.png', '0114.png', '0175.png', '0291.png', '0695.png', '0717.png', '0772.png', '0156.png', '0555.png', '0216.png', '0265.png', '0544.png', '0671.png', '0186.png', '0281.png', '0339.png', '0154.png', '0765.png', '0775.png', '0280.png', '0507.png', '0217.png', '0245.png', '0679.png', '0512.png', '0305.png', '0490.png', '0639.png', '0083.png', '0313.png', '0706.png', '0474.png', '0452.png', '0760.png', '0714.png', '0737.png', '0542.png', '0326.png', '0019.png', '0605.png', '0647.png', '0602.png', '0041.png', '0185.png', '0788.png', '0179.png', '0626.png', '0235.png', '0010.png', '0471.png', '0504.png', '0531.png', '0309.png', '0541.png', '0721.png', '0726.png', '0345.png', '0229.png', '0489.png', '0440.png', '0007.png', '0302.png', '0610.png', '0228.png', '0283.png', '0111.png', '0145.png', '0761.png', '0149.png', '0380.png', '0377.png', '0085.png', '0756.png', '0045.png', '0651.png', '0581.png', '0723.png', '0199.png', '0403.png', '0078.png', '0046.png', '0538.png', '0375.png', '0137.png', '0076.png', '0715.png', '0572.png', '0220.png', '0330.png', '0365.png', '0096.png', '0282.png', '0470.png', '0161.png', '0641.png', '0611.png', '0178.png', '0643.png', '0286.png', '0434.png', '0463.png', '0139.png', '0637.png', '0068.png', '0678.png', '0404.png', '0289.png', '0444.png', '0157.png', '0066.png', '0200.png', '0118.png', '0437.png', '0335.png', '0745.png', '0274.png', '0101.png', '0221.png', '0239.png', '0661.png', '0238.png', '0327.png', '0385.png', '0426.png', '0306.png', '0369.png', '0624.png', '0243.png', '0170.png', '0087.png', '0530.png', '0784.png', '0614.png', '0162.png', '0224.png', '0039.png', '0318.png', '0433.png', '0503.png', '0537.png', '0487.png', '0347.png', '0754.png', '0184.png', '0764.png', '0436.png', '0188.png', '0787.png', '0005.png', '0700.png', '0771.png', '0693.png', '0123.png', '0786.png', '0325.png', '0371.png', '0033.png', '0732.png', '0373.png', '0496.png', '0615.png', '0688.png', '0609.png', '0523.png', '0054.png', '0166.png', '0456.png', '0105.png', '0673.png']\n",
            "[TL] Number of files = 800\n",
            "[TL] read 32 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 64 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 96 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 128 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 160 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 192 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 224 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 256 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 288 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 320 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 352 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 384 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 416 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 448 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 480 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 512 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 544 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 576 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 608 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 640 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 672 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 704 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 736 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 768 from /tmp/Dataset/DIV2K_train_HR/\n",
            "[TL] read 800 from /tmp/Dataset/DIV2K_train_HR/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQceOlKGyCfq",
        "colab_type": "text"
      },
      "source": [
        "## Model Inialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNhuUqpoyHxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan_generator = model_generator()\n",
        "gan_generator.load_weights(PATH_PRE_GENERATOR)\n",
        "\n",
        "discriminator = model_discriminator()\n",
        "\n",
        "# 5 or 20\n",
        "VGG = model_vgg19(output_layer=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIT9ajiSNQ9N",
        "colab_type": "text"
      },
      "source": [
        "## Save Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDRHnomTNNl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=gan_generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                                    directory=checkpoint_dir,\n",
        "                                                    max_to_keep=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPWQ6kS1tJL1",
        "colab_type": "text"
      },
      "source": [
        "## Losses\n",
        "**Generator**  -- We used Perceptual Loss, It's Sum Of Two Function: \n",
        "* Content Loss: 1) Pixel-wise MSE Loss. 2) VGG Loss\n",
        "* Adversarial loss - It's probability of Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suv9IJ_XM8VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# G Loss\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "# D Loss\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# Content Loss (VGG 19)\n",
        "@tf.function\n",
        "def _content_loss(vgg_model, gen_fake, hr):\n",
        "  gen_fake = (gen_fake + 1) / 2. # VGG19 used [0, 1]\n",
        "  hr = (hr + 1) / 2.\n",
        "  gen_fake_features = vgg_model(gen_fake) \n",
        "  hr_features = vgg_model(hr) \n",
        "\n",
        "  return tf.keras.losses.MeanSquaredError()(hr_features, gen_fake_features)\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_2lQox4NcgL",
        "colab_type": "text"
      },
      "source": [
        "## Training Steps "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXBb9rIwNevE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(lr, hr):\n",
        "  \"\"\"\n",
        "      lr - low resolution image x\n",
        "      hr - high resolution image y \n",
        "  \"\"\"\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = gan_generator(lr, training=True)\n",
        "    real_output = discriminator(hr, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    \n",
        "    # G loss\n",
        "    mse_loss = tf.keras.losses.MeanSquaredError()(generated_images, hr)\n",
        "    content_loss  = _content_loss(VGG, generated_images, hr)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "  \n",
        "    perceptual_loss = content_loss * 1e-3 + 2e-6 * gen_loss + mse_loss\n",
        "\n",
        "    # D loss\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    \n",
        "  # Backprop for G\n",
        "  gradients_of_generator = gen_tape.gradient(perceptual_loss, gan_generator.trainable_variables)\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, gan_generator.trainable_variables))\n",
        "  \n",
        "  # Backprop for D\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "  return disc_loss, perceptual_loss, generated_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FzEyMtgNpv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs, batch_size, writer):\n",
        "  perceptual_metric = Mean()\n",
        "  disc_metric = Mean()\n",
        "\n",
        "  n_step_epoch = round(epochs // batch_size)\n",
        "\n",
        "  for epoch in range(n_step_epoch):\n",
        "    start = time.time()\n",
        "    for step, (lr, hr) in enumerate(train_ds):\n",
        "      disc_loss, perceptual_loss, gen_images = train_step(lr, hr)\n",
        "      \n",
        "      perceptual_metric(perceptual_loss)\n",
        "      disc_metric(disc_loss)\n",
        "      \n",
        "    # Save Model Every 10 Epochs\n",
        "    if (epoch) % 3 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)  \n",
        "      \n",
        "      tl.vis.save_images(gen_images.numpy(), [2, 4], os.path.join(PATH_FOR_SAVE_GEN_IMAGES, 'train_g_{}.png'.format(epoch)))\n",
        "      \n",
        "      gan_generator.save(os.path.join(PATH_FOR_SAVE_MODELS, 'generator-{}.h5'.format(epoch)))\n",
        "      discriminator.save(os.path.join(PATH_FOR_SAVE_MODELS, 'discriminator-{}.h5'.format(epoch)))\n",
        "      print('P Loss', perceptual_metric.result())\n",
        "      print('D Lost', disc_metric.result())\n",
        "\n",
        "      perceptual_metric.reset_states()\n",
        "      disc_metric.reset_states()\n",
        "      \n",
        "    print ('Time for epoch {} of {} is {} sec'.format(epoch + 1, n_step_epoch, int(time.time()-start)))\n",
        "  gan_generator.save(os.path.join(PATH_FOR_SAVE_MODELS, 'generator-final.h5'))\n",
        "  discriminator.save(os.path.join(PATH_FOR_SAVE_MODELS, 'discriminator-final.h5'))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAV-yF_uB8ru",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_c2gWLrZat",
        "colab_type": "code",
        "outputId": "2fc1fd98-04de-4284-f174-9d1091f61bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(train_ds, EPOCHS, BATCH_SIZE, train_summary_writer)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P Loss tf.Tensor(18.922638, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.31444302, shape=(), dtype=float32)\n",
            "Time for epoch 1 of 80 is 104 sec\n",
            "Time for epoch 2 of 80 is 100 sec\n",
            "Time for epoch 3 of 80 is 99 sec\n",
            "P Loss tf.Tensor(18.569492, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.2575065, shape=(), dtype=float32)\n",
            "Time for epoch 4 of 80 is 103 sec\n",
            "Time for epoch 5 of 80 is 100 sec\n",
            "Time for epoch 6 of 80 is 100 sec\n",
            "P Loss tf.Tensor(18.01409, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.00516451, shape=(), dtype=float32)\n",
            "Time for epoch 7 of 80 is 104 sec\n",
            "Time for epoch 8 of 80 is 101 sec\n",
            "Time for epoch 9 of 80 is 101 sec\n",
            "P Loss tf.Tensor(18.182432, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.2719872, shape=(), dtype=float32)\n",
            "Time for epoch 10 of 80 is 106 sec\n",
            "Time for epoch 11 of 80 is 101 sec\n",
            "Time for epoch 12 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.701242, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.08752858, shape=(), dtype=float32)\n",
            "Time for epoch 13 of 80 is 105 sec\n",
            "Time for epoch 14 of 80 is 101 sec\n",
            "Time for epoch 15 of 80 is 100 sec\n",
            "P Loss tf.Tensor(17.52826, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.22701001, shape=(), dtype=float32)\n",
            "Time for epoch 16 of 80 is 103 sec\n",
            "Time for epoch 17 of 80 is 100 sec\n",
            "Time for epoch 18 of 80 is 100 sec\n",
            "P Loss tf.Tensor(17.641502, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.06706993, shape=(), dtype=float32)\n",
            "Time for epoch 19 of 80 is 103 sec\n",
            "Time for epoch 20 of 80 is 100 sec\n",
            "Time for epoch 21 of 80 is 100 sec\n",
            "P Loss tf.Tensor(17.339075, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.020322507, shape=(), dtype=float32)\n",
            "Time for epoch 22 of 80 is 104 sec\n",
            "Time for epoch 23 of 80 is 101 sec\n",
            "Time for epoch 24 of 80 is 102 sec\n",
            "P Loss tf.Tensor(17.62064, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(4.0897157e-05, shape=(), dtype=float32)\n",
            "Time for epoch 25 of 80 is 106 sec\n",
            "Time for epoch 26 of 80 is 101 sec\n",
            "Time for epoch 27 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.50899, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(5.1737683e-05, shape=(), dtype=float32)\n",
            "Time for epoch 28 of 80 is 104 sec\n",
            "Time for epoch 29 of 80 is 101 sec\n",
            "Time for epoch 30 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.411201, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.2020965, shape=(), dtype=float32)\n",
            "Time for epoch 31 of 80 is 118 sec\n",
            "Time for epoch 32 of 80 is 101 sec\n",
            "Time for epoch 33 of 80 is 100 sec\n",
            "P Loss tf.Tensor(17.130295, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.0044163764, shape=(), dtype=float32)\n",
            "Time for epoch 34 of 80 is 103 sec\n",
            "Time for epoch 35 of 80 is 100 sec\n",
            "Time for epoch 36 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.396492, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.087371945, shape=(), dtype=float32)\n",
            "Time for epoch 37 of 80 is 105 sec\n",
            "Time for epoch 38 of 80 is 100 sec\n",
            "Time for epoch 39 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.455069, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.0028424119, shape=(), dtype=float32)\n",
            "Time for epoch 40 of 80 is 105 sec\n",
            "Time for epoch 41 of 80 is 101 sec\n",
            "Time for epoch 42 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.727535, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(0.07497685, shape=(), dtype=float32)\n",
            "Time for epoch 43 of 80 is 105 sec\n",
            "Time for epoch 44 of 80 is 101 sec\n",
            "Time for epoch 45 of 80 is 101 sec\n",
            "P Loss tf.Tensor(17.21399, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(4.2484764e-05, shape=(), dtype=float32)\n",
            "Time for epoch 46 of 80 is 104 sec\n",
            "Time for epoch 47 of 80 is 99 sec\n",
            "Time for epoch 48 of 80 is 99 sec\n",
            "P Loss tf.Tensor(17.622124, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(6.709447e-07, shape=(), dtype=float32)\n",
            "Time for epoch 49 of 80 is 103 sec\n",
            "Time for epoch 50 of 80 is 99 sec\n",
            "Time for epoch 51 of 80 is 99 sec\n",
            "P Loss tf.Tensor(17.297733, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(3.576196e-08, shape=(), dtype=float32)\n",
            "Time for epoch 52 of 80 is 102 sec\n",
            "Time for epoch 53 of 80 is 100 sec\n",
            "Time for epoch 54 of 80 is 100 sec\n",
            "P Loss tf.Tensor(17.378101, shape=(), dtype=float32)\n",
            "D Lost tf.Tensor(5.746417e-06, shape=(), dtype=float32)\n",
            "Time for epoch 55 of 80 is 103 sec\n",
            "Time for epoch 56 of 80 is 99 sec\n",
            "Time for epoch 57 of 80 is 98 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-62f614ddba93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-48f789bbbc0b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs, batch_size, writer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperceptual_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mperceptual_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptual_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-e552353324e7>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(lr, hr)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Backprop for D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    590\u001b[0m   \"\"\"\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   8281\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   8282\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8283\u001b[0;31m         tld.op_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   8284\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8285\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}